{"cells":[{"cell_type":"markdown","source":["## Cross Validation Split\n\nNext important import statements for trying cross validation"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"72a681ab-3dc5-47f8-9678-2793a465911b"}}},{"cell_type":"code","source":["from pyspark.sql.functions import percent_rank\nfrom pyspark.sql import Window\nfrom datetime import datetime, date\nfrom pyspark.sql import Row"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"5479cd36-374e-47f4-813b-e5a43e4d2ec4"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["One key part of cross validation is splitting the data into the different folds for model evaluation. Below if a function to take a full training dataframe and return three lists that contain each fold of the training data, validation data, and test data. The split occurs by ordering the data by a specific time column, adding a `rank` column which specifies what percentile of the ordered data a specific data point is in, and splitting based on the different percentages."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"64b518b8-fec9-46a3-8b4a-7319476c0312"}}},{"cell_type":"code","source":["def time_series_cross_validation_split(num_folds, df, sort_order_column_name, dependent_column_name):\n  \n  \"\"\"\n  Parameters\n  ----------\n    num_folds : int\n      The number of folds for which to split the data\n    df : dataframe\n      The base dataframe for which to split\n    sort_order_column_name : str\n      The column for which the dataframe should be sorted by for ranking purposes\n    dependent_column_name : str\n      The column name for the dependent variable in the model\n  \"\"\"\n  \n  # Sanity check on datafram\n  if sort_order_column_name not in df.columns or dependent_column_name not in df.columns:\n    return\n  # Add rank column\n  df = df.withColumn(\"rank\", percent_rank().over(Window.partitionBy().orderBy(sort_order_column_name)))\n  # Define percentages on which to split data based on rank and number of folds\n  fold_percentage = 1 / (num_folds + 2)\n  df_train_list = []\n  df_validate_list = []\n  df_test_list = []\n  \n  # For each fold\n  for i in range(1, num_folds + 1):\n    # Define train df\n    train_df = df.where(\"rank <= \" + str(fold_percentage * i)).drop(\"rank\")\n    # Define validation df\n    validate_df = df.where(\"rank <= \" + str(fold_percentage * (i + 1)) + \" and rank > \" + str(fold_percentage * i)).drop(\"rank\")\n    # Define test df\n    test_df = df.where(\"rank <= \" + str(fold_percentage * (i + 2)) + \" and rank > \" + str(fold_percentage * (i + 1))).drop(\"rank\")\n    \n    # Append to lists to return \n    df_train_list.append(train_df)\n    df_validate_list.append(validate_df)\n    df_test_list.append(test_df)\n  return df_train_list, df_validate_list, df_test_list"],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"94d8f17d-b1da-4539-be92-df9ffd0088c7"}},"outputs":[{"output_type":"display_data","metadata":{"application/vnd.databricks.v1+output":{"datasetInfos":[],"data":"<div class=\"ansiout\"></div>","removedWidgets":[],"addedWidgets":{},"metadata":{},"type":"html","arguments":{}}},"output_type":"display_data","data":{"text/html":["<style scoped>\n  .ansiout {\n    display: block;\n    unicode-bidi: embed;\n    white-space: pre-wrap;\n    word-wrap: break-word;\n    word-break: break-all;\n    font-family: \"Source Code Pro\", \"Menlo\", monospace;;\n    font-size: 13px;\n    color: #555;\n    margin-left: 4px;\n    line-height: 19px;\n  }\n</style>\n<div class=\"ansiout\"></div>"]}}],"execution_count":0},{"cell_type":"markdown","source":["For a three fold validation, the function would divide the data into five equal slices. In the first fold, the training data would be the first fifth of the data, the validation the second fifth, and the training the third fifth. In the second fold, the training data would be the first two fifths of the data, the validation set the third fifth, and the test set the fourth fifth.\n\nThis function allows any data set to be easily split into proper training, validation, and test folds that any model can utilize for error estimation and hyperparameter tuning. It will be used in modeling sections later in the report."],"metadata":{"application/vnd.databricks.v1+cell":{"title":"","showTitle":false,"inputWidgets":{},"nuid":"0e6da5e2-a0b5-4f0e-b3d4-157340352505"}}}],"metadata":{"application/vnd.databricks.v1+notebook":{"notebookName":"cross_validation","dashboards":[],"notebookMetadata":{"pythonIndentUnit":2},"language":"python","widgets":{},"notebookOrigID":418875703315306}},"nbformat":4,"nbformat_minor":0}
